# 컨텍스트 윈도우(Context Window)란?

## 1. 컨텍스트 윈도우의 정의

LLM(Large Language Model)에서 **컨텍스트 윈도우**란 모델이 한 번에 처리할 수 있는 텍스트의 범위를 의미함. 

모델이 텍스트를 이해하거나 예측할 때, 동시에 참조할 수 있는 단어 또는 토큰의 수를 제한하는 창(window)임.

즉, 모델이 한 번에 처리할 수 있는 **최대 입출력 토큰 수(최대 토큰 길이)**

## 2. 컨텍스트 윈도우의 역할

컨텍스트 윈도우는 모델이 텍스트 내에서 문맥을 파악하고, 그에 따라 적절한 응답을 생성하는 데 매우 중요한 역할을 함. 윈도우 크기가 클수록 모델은 더 많은 문맥 정보를 바탕으로 예측할 수 있지만, 그만큼 계산 비용도 증가함.

### 예시
다음과 같은 문장을 보자:
> "지난 주말에 나는 친구들과 산책을 하면서 여러 가지 이야기를 나눴다. 그 중 가장 기억에 남는 것은…"

이 문장에서 모델이 "가장 기억에 남는 것"에 대한 응답을 생성할 때, 앞에서 주어진 전체 문장을 기반으로 답을 제공할 수 있음. 하지만 만약 컨텍스트 윈도우가 작아서 "지난 주말에 나는"까지만 참고할 수 있다면, 모델이 나머지 정보를 인식하지 못해 잘못된 응답을 할 가능성이 있음.

## 3. 토큰과 컨텍스트 윈도우

LLM은 텍스트를 '토큰'으로 나누어 처리함. 따라서 컨텍스트 윈도우의 크기는 처리할 수 있는 **토큰의 수**를 나타냄. 토큰은 단어, 부분 단어, 문장 부호 등으로 이루어져 있기 때문에, 실제 문장의 길이는 토큰 수에 따라 달라질 수 있음. 예를 들어, 다음 두 문장은 각각 다른 토큰 수를 가질 수 있음:

- "Artificial Intelligence" (2개의 토큰)
- "AI" (1개의 토큰)

이렇게 문장의 길이와 토큰 수가 다를 수 있기 때문에, 긴 문장을 처리하려면 더 큰 컨텍스트 윈도우가 필요함.

## 4. 컨텍스트 윈도우의 한계

모델은 한 번에 처리할 수 있는 토큰 수가 제한되어 있음. 즉, 컨텍스트 윈도우가 초과되는 길이의 텍스트가 입력되면, 처음 부분이나 끝 부분의 정보를 손실할 수 있음.

예를 들어, 5000개의 토큰이 있는 긴 문서에서 모델이 4096개의 토큰만 처리할 수 있다면, 나머지 904개의 토큰은 무시됨. 이 경우 중요한 정보가 손실될 수 있어, 텍스트를 나누어 처리하거나 적절한 부분만 발췌하여 입력하는 전략이 필요함.

## 5. 컨텍스트 윈도우 최적화

컨텍스트 윈도우를 최적화하기 위해서는 다음과 같은 방법을 고려할 수 있음:

- **짧고 중요한 정보 우선**: 긴 텍스트에서 중요한 부분만 발췌하여 모델에 입력.
- **윈도우 크기 확장**: 최신 모델들은 더 큰 컨텍스트 윈도우를 제공하여 더 많은 정보를 처리할 수 있도록 함. 예를 들어 GPT-4는 최대 32,768개의 토큰을 처리할 수 있는 컨텍스트 윈도우를 제공함.

## 6. 결론

컨텍스트 윈도우는 LLM이 한 번에 처리할 수 있는 텍스트의 크기를 결정하는 중요한 요소임. 윈도우의 크기가 클수록 더 많은 문맥을 반영할 수 있지만, 그에 따른 계산 비용도 증가함. 적절한 토큰화와 문맥 처리 전략을 사용하여 컨텍스트 윈도우의 한계를 극복하는 것이 중요함.

<a href="https://www.flaticon.com/kr/free-icons/ai-" title="ai 애플리케이션 아이콘">Ai 애플리케이션 아이콘 제작자: Iconfromus - Flaticon</a>