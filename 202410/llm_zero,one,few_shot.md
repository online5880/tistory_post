# LLM에서 Zero-shot, One-shot, Few-shot 학습

대규모 언어 모델(LLM, Large Language Model)에서 흔히 언급되는 학습 방식으로 **Zero-shot**, **One-shot**, **Few-shot** 학습이 있음. 

이 방식들은 주어진 과제에서 모델이 얼마나 많은 예시를 보고 학습해야 하는지를 기준으로 나누어지며, 각각의 개념을 아래에서 자세히 설명함.

## 1. Zero-shot 학습

**Zero-shot 학습**은 모델이 특정 과제에 대해 **아무런 예시를 제공받지 않은 상태에서** 바로 문제를 해결하는 능력을 말함. 이는 LLM이 방대한 데이터로 사전 학습되었기 때문에 새로운 과제에 대해 일반화된 지식을 적용할 수 있다는 것을 의미함.

- 예시: 모델에게 "한글로 번역해보세요: 'The sky is blue.'"라고 했을 때, 번역 예시를 한 번도 보지 않았더라도 학습된 언어적 지식을 활용해 "하늘은 파랗다."라고 번역함.

### 장점
- **새로운 작업에 대한 유연성**: 예시가 없더라도 문제를 해결 가능.
- **빠른 응답**: 학습이 필요 없기 때문에 추가 데이터 준비 없이 즉각적으로 사용 가능.

### 단점
- **정확도**: 과제의 복잡도에 따라 성능이 떨어질 수 있음. 충분한 예시가 없는 경우, 모델의 추론이 불안정할 수 있음.

## 2. One-shot 학습

**One-shot 학습**은 **단 하나의 예시만**을 제공한 상태에서 모델이 새로운 문제를 해결하는 방식임. 이는 Few-shot 학습과 유사하지만 예시의 수가 1개로 제한된다는 점이 다름.

- 예시: "The sky is blue." → "하늘은 파랗다."라는 번역 예시 하나만 보고 이후에 "The grass is green."을 번역하라고 요청했을 때, 이를 "잔디는 초록색이다."라고 번역하는 방식.

### 장점
- **빠른 적응**: 단 하나의 예시로도 학습이 가능하다는 점에서 효율적임.
- **높은 일반화 능력**: 사전 학습을 잘 활용하여 최소한의 정보로도 과제를 해결.

### 단점
- **과제 복잡도에 민감**: 하나의 예시만으로 모든 문제를 해결하기 어렵거나 오해할 가능성 있음.

## 3. Few-shot 학습

**Few-shot 학습**은 모델이 특정 과제에 대해 **소수의 예시만을 보고** 문제를 해결하는 방식임. 일반적으로 1~5개의 예시가 주어지며, 모델은 이러한 예시를 통해 문제 해결 방식을 학습함.

- 예시: 모델에게 몇 가지 번역 예시("The sky is blue." → "하늘은 파랗다.", "The cat is small." → "고양이는 작다.")를 보여준 후 새로운 문장을 번역하게 함.

### 장점
- **적응력**: 예시 몇 개만으로도 모델이 과제의 패턴을 이해할 수 있음.
- **효율성**: 다량의 데이터 없이도 성능 향상이 가능.

### 단점
- **예시의 품질 의존**: 주어진 예시가 과제에 적합하지 않으면 성능이 떨어질 수 있음.

## 요약

| 학습 방식   | 예시 수   | 장점                                    | 단점                                    |
|-------------|-----------|-----------------------------------------|-----------------------------------------|
| Zero-shot   | 0         | 새로운 작업에도 바로 적용 가능           | 복잡한 과제에서 성능 저하 가능           |
| One-shot    | 1         | 단일 예시로 빠르게 학습 가능             | 하나의 예시만으로는 충분하지 않을 수 있음 |
| Few-shot    | 1~5       | 적은 예시로도 문제 해결 가능             | 예시 품질에 따라 성능 변동 가능          |
